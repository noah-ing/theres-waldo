# Scale-aware Vision Transformer configuration (CPU-optimized)
num_heads: 8  # Proven optimal for our task
num_layers: 8  # Balance between capacity and speed
hidden_dim: 512  # Sufficient for feature extraction
mlp_dim: 2048  # Proven effective dimension
dropout_rate: 0.4  # Increased for better regularization

# Scale-aware parameters
scale_bins: [0.05, 0.075, 0.1, 0.125, 0.15]  # Aligned with training config
attention_dropout_rate: 0.3  # Increased for better generalization

# Training parameters
weight_decay: 0.2  # Increased for stronger regularization
max_grad_norm: 0.5  # Reduced for more stable updates
gradient_checkpointing: false  # CPU compatibility

# Scale-aware optimization
scale_aware:
  enabled: true
  size_weights: [3.0, 2.0, 1.0, 2.0, 3.0]  # Aligned with training config
  adaptive_loss: true
  size_normalization: true

# Enhanced augmentation
augmentation:
  random_flip: true
  color_jitter:
    brightness: 0.6  # Increased for better generalization
    contrast: 0.6
    saturation: 0.6
    hue: 0.2
